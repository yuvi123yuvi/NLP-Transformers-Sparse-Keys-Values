{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Check Which GPU you got"
      ],
      "metadata": {
        "id": "xEUs64r2Chb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKT8Ev9vC0tG",
        "outputId": "6ea5e595-431a-4463-dcf7-5b95064eec38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 27 22:08:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports and CONST"
      ],
      "metadata": {
        "id": "PvpKt_-tBWJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK661-DMwuEw",
        "outputId": "29865ffa-8be7-4006-9ca6-83eba9557d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Model, GPT2Tokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "DATA_FILE_DIR = \"/content/drive/My Drive/NLP-Final/GPT2-News-Classifier/data/\"\n",
        "STATE_FILE_DIR = \"/content/drive/My Drive/NLP-Final/\"\n",
        "KEYS_VALUES_PATH = \"/content/drive/My Drive/NLP-Final/gpt2_sparse_keys&values/\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definitions"
      ],
      "metadata": {
        "id": "qggWM8tyYNMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgAXuu6tw9kX"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "        tokenizer.padding_side = \"left\"\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        labels = {\n",
        "            \"business\": 0,\n",
        "            \"entertainment\": 1,\n",
        "            \"sport\": 2,\n",
        "            \"tech\": 3,\n",
        "            \"politics\": 4\n",
        "                }\n",
        "        self.labels = [labels[label] for label in df['category']]\n",
        "        self.texts = [tokenizer(text,\n",
        "                                padding='max_length',\n",
        "                                max_length=128,\n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "        \n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def get_batch_labels(self, idx):\n",
        "        # Get a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "    \n",
        "    def get_batch_texts(self, idx):\n",
        "        # Get a batch of inputs\n",
        "        return self.texts[idx]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lhn6FYQVyhDX"
      },
      "outputs": [],
      "source": [
        "class GPT2SequenceClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int):\n",
        "        super(GPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(\"gpt2\")\n",
        "        self.fc1 = nn.Linear(hidden_size*max_seq_len, num_classes)\n",
        "\n",
        "        \n",
        "    def forward(self, input_id, mask):\n",
        "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
        "        return linear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2doVjPr8y4fK"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_data, val_data, learning_rate, epochs):\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "    \n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "    \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "        \n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_input['attention_mask'].to(device)\n",
        "            input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
        "            \n",
        "            model.zero_grad()\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "            \n",
        "            batch_loss = criterion(output, train_label)\n",
        "            total_loss_train += batch_loss.item()\n",
        "            \n",
        "            acc = (output.argmax(dim=1)==train_label).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            \n",
        "            for val_input, val_label in val_dataloader:\n",
        "                val_label = val_label.to(device)\n",
        "                mask = val_input['attention_mask'].to(device)\n",
        "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "                \n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, val_label)\n",
        "                total_loss_val += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1)==val_label).sum().item()\n",
        "                total_acc_val += acc\n",
        "                \n",
        "            print(\n",
        "            f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train/len(train_data): .3f} \\\n",
        "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "            | Val Accuracy: {total_acc_val / len(val_data): .3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DRp86KKzFBZ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "        \n",
        "    # Tracking variables\n",
        "    predictions_labels = []\n",
        "    true_labels = []\n",
        "    \n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_input['attention_mask'].to(device)\n",
        "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "\n",
        "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "            total_acc_test += acc\n",
        "            \n",
        "            # add original labels\n",
        "            true_labels += test_label.cpu().numpy().flatten().tolist()\n",
        "            # get predicitons to list\n",
        "            predictions_labels += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
        "\n",
        "            # send back to cpu\n",
        "            test_label = test_label.to(\"cpu\")\n",
        "            mask = test_input['attention_mask'].to(\"cpu\")\n",
        "            input_id = test_input['input_ids'].squeeze(1).to(\"cpu\")\n",
        "\n",
        "    test_accuracy = total_acc_test / len(test_data)\n",
        "    print(f'Test Accuracy: {test_accuracy:.3f}')\n",
        "    model.cpu()             # send back to cpu\n",
        "    return test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Fast OMP"
      ],
      "metadata": {
        "id": "PFe-P-eNVKDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext Cython"
      ],
      "metadata": {
        "id": "xkzCMB4NXOOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cython\n",
        "\n",
        "\"\"\"Cython allows us to call lower level c-code instead of using Python. It can be a surprisingly big speedup!\"\"\"\n",
        "import cython\n",
        "from scipy.linalg.cython_blas cimport idamax, isamax, daxpy, dgemv, dtrmv, dcopy\n",
        "from scipy.linalg.cython_lapack cimport dposv, dppsv, sppsv\n",
        "\n",
        "ctypedef fused proj_t:\n",
        "    double\n",
        "    float\n",
        "\n",
        "@cython.boundscheck(False)\n",
        "@cython.wraparound(False)\n",
        "cpdef void ppsv(proj_t[:, :] As,\n",
        "           proj_t[:, :, :] ys) nogil:\n",
        "    # Works not for strided array I think. And please do not give a negative-stride array.\n",
        "    cdef Py_ssize_t B = ys.shape[0]  # Batch size\n",
        "    cdef int N = ys.shape[1]\n",
        "    cdef int nrhs = ys.shape[2]\n",
        "    cdef int info = 0  # Just discard any error signals ;)\n",
        "    cdef char uplo = 85 # The letter 'U', since we store the lower triangle and fortran sees As.T.\n",
        "    # cdef int ldb = ys[0].strides[0] // sizeof(double)\n",
        "\n",
        "    for i from 0 <= i < B:\n",
        "        if proj_t is double:  # One C-function is created for each of these specializations! :) (see argmax_blast.__signatures__)\n",
        "            dppsv(&uplo, &N, &nrhs, &As[i, 0], &ys[i, 0, 0], &N, &info)\n",
        "        elif proj_t is float:\n",
        "            sppsv(&uplo, &N, &nrhs, &As[i, 0], &ys[i, 0, 0], &N, &info)\n",
        "\n",
        "\n",
        "@cython.boundscheck(False)\n",
        "@cython.wraparound(False)\n",
        "cpdef void argmax_blast(proj_t[:, :] projections,\n",
        "                 long long[:] output) nogil:\n",
        "    # TODO: Numpy has its own indexing data-type - this may be a more appropriate output, and may even be faster.\n",
        "    # http://conference.scipy.org/static/wiki/seljebotn_cython.pdf\n",
        "    # https://apprize.best/python/cython/3.html\n",
        "    cdef Py_ssize_t B = projections.shape[0]\n",
        "    cdef int N = projections.shape[1]\n",
        "    cdef int incx = projections.strides[1] // sizeof(proj_t)  # Stride between elements.\n",
        "    cdef Py_ssize_t i\n",
        "    for i from 0 <= i < B:\n",
        "        if proj_t is double:\n",
        "            output[i] = idamax(&N, &projections[i, 0], &incx) - 1\n",
        "        elif proj_t is float:\n",
        "            output[i] = isamax(&N, &projections[i, 0], &incx) - 1"
      ],
      "metadata": {
        "id": "Z9R-3TkWYdkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"This cell contains the code we've implemented. You should be able to call each function directly, or alternatively, see our example calls below\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "from sklearn.datasets import make_sparse_coded_signal\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "from contextlib import contextmanager\n",
        "from timeit import default_timer\n",
        "# from test_omp import omp_naive\n",
        "# from test import *  # FIXME: better name\n",
        "# from line_profiler import line_profiler\n",
        "\n",
        "n_components, n_features = 100, 100\n",
        "n_nonzero_coefs = 17\n",
        "n_samples = 50\n",
        "\n",
        "@contextmanager\n",
        "def elapsed_timer():\n",
        "    # https://stackoverflow.com/questions/7370801/how-to-measure-elapsed-time-in-python\n",
        "    start = default_timer()\n",
        "    elapser = lambda: default_timer() - start\n",
        "    yield lambda: elapser()\n",
        "    end = default_timer()\n",
        "    elapser = lambda: end-start\n",
        "\n",
        "\n",
        "def run_omp(X, y, n_nonzero_coefs, precompute=True, tol=0.0, normalize=False, fit_intercept=False, alg='naive'):\n",
        "    if not isinstance(X, torch.Tensor):\n",
        "        X = torch.as_tensor(X)\n",
        "        y = torch.as_tensor(y)\n",
        "\n",
        "    # We can either return sets, (sets, solutions), or xests\n",
        "    # These are all equivalent, but are simply more and more dense representations.\n",
        "    # Given sets and X and y one can (re-)construct xests. The second is just a sparse vector repr.\n",
        "\n",
        "    # https://github.com/scikit-learn/scikit-learn/blob/15a949460dbf19e5e196b8ef48f9712b72a3b3c3/sklearn/linear_model/_omp.py#L690\n",
        "    if fit_intercept or normalize:\n",
        "        X = X.clone()\n",
        "        assert not isinstance(precompute, torch.Tensor), \"If user pre-computes XTX they can also pre-normalize X\" \\\n",
        "                                                         \" as well, so normalize and fit_intercept must be set false.\"\n",
        "\n",
        "    if fit_intercept:\n",
        "        X = X - X.mean(0)\n",
        "        y = y - y.mean(1)[:, None]\n",
        "\n",
        "    # To keep a good condition number on X, especially with Cholesky compared to LU factorization,\n",
        "    # we should probably always normalize it (OMP is invariant anyways)\n",
        "    if normalize is True:  # User can also just optionally supply pre-computed norms.\n",
        "        normalize = (X * X).sum(0).sqrt()\n",
        "        X /= normalize[None, :]\n",
        "\n",
        "    if precompute is True or alg == 'v0':\n",
        "        precompute = X.T @ X\n",
        "\n",
        "    # If n_nonzero_coefs is equal to M, one should just return lstsq\n",
        "    if alg == 'naive':\n",
        "        sets, solutions, lengths = omp_naive(X, y, n_nonzero_coefs=n_nonzero_coefs, XTX=precompute, tol=tol)\n",
        "    elif alg == 'v0':\n",
        "        sets, solutions, lengths = omp_v0(X, y, n_nonzero_coefs=n_nonzero_coefs, XTX=precompute, tol=tol)\n",
        "\n",
        "\n",
        "    solutions = solutions.squeeze(-1)\n",
        "    if normalize is not False:\n",
        "        solutions /= normalize[sets]\n",
        "\n",
        "    xests = y.new_zeros(y.shape[0], X.shape[1])\n",
        "    if lengths is None:\n",
        "        xests[torch.arange(y.shape[0], dtype=sets.dtype, device=sets.device)[:, None], sets] = solutions\n",
        "    else:\n",
        "        for i in range(y.shape[0]):\n",
        "            # xests[i].scatter_(-1, sets[i, :lengths[i]], solutions[i, :lengths[i]])\n",
        "            xests[i, sets[i, :lengths[i]]] = solutions[i, :lengths[i]]\n",
        "\n",
        "    return xests\n",
        "\n",
        "def batch_mm(matrix, matrix_batch, return_contiguous=True):\n",
        "    \"\"\"\n",
        "    :param matrix: Sparse or dense matrix, size (m, n).\n",
        "    :param matrix_batch: Batched dense matrices, size (b, n, k).\n",
        "    :return: The batched matrix-matrix product, size (m, n) x (b, n, k) = (b, m, k).\n",
        "    \"\"\"\n",
        "    # One dgemm is faster than many dgemv.\n",
        "    # From https://github.com/pytorch/pytorch/issues/14489#issuecomment-607730242\n",
        "    batch_size = matrix_batch.shape[0]\n",
        "    # Stack the vector batch into columns. (b, n, k) -> (n, b, k) -> (n, b*k)\n",
        "    vectors = matrix_batch.transpose([1, 0, 2]).reshape(matrix.shape[1], -1)\n",
        "\n",
        "    # A matrix-matrix product is a batched matrix-vector product of the columns.\n",
        "    # And then reverse the reshaping. (m, n) x (n, b*k) = (m, b*k) -> (m, b, k) -> (b, m, k)\n",
        "    if return_contiguous:\n",
        "        result = np.empty_like(matrix_batch, shape=(batch_size, matrix.shape[0], matrix_batch.shape[2]))\n",
        "        np.matmul(matrix, vectors, out=result.transpose([1, 0, 2]).reshape(matrix.shape[0], -1))\n",
        "    else:\n",
        "        result = (matrix @ vectors).reshape(matrix.shape[0], batch_size, -1).transpose([1, 0, 2])\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def innerp(x, y=None, out=None):\n",
        "    if y is None:\n",
        "        y = x\n",
        "    if out is not None:\n",
        "        out = out[:, None, None]  # Add space for two singleton dimensions.\n",
        "    return torch.matmul(x[..., None, :], y[..., :, None], out=out)[..., 0, 0]\n",
        "\n",
        "def cholesky_solve(ATA, ATy):\n",
        "    if ATA.dtype == torch.half or ATy.dtype == torch.half:\n",
        "        return ATy.to(torch.float).cholesky_solve(torch.cholesky(ATA.to(torch.float))).to(ATy.dtype)\n",
        "    return ATy.cholesky_solve(torch.cholesky(ATA)).to(ATy.dtype)\n",
        "\n",
        "\n",
        "def omp_naive(X, y, n_nonzero_coefs, tol=None, XTX=None):\n",
        "    on_cpu = not (y.is_cuda or y.dtype == torch.half)\n",
        "    # torch.cuda.synchronize()\n",
        "    # Given X as an MxN array and y as an BxN array, do omp to approximately solve Xb=y\n",
        "\n",
        "    # Base variables\n",
        "    XT = X.contiguous().t()  # Store XT in fortran-order.\n",
        "    y = y.contiguous()\n",
        "    r = y.clone()\n",
        "\n",
        "    sets = y.new_zeros((n_nonzero_coefs, y.shape[0]), dtype=torch.long).t()\n",
        "    if tol:\n",
        "        result_sets = sets.new_zeros(y.shape[0], n_nonzero_coefs)\n",
        "        result_lengths = sets.new_zeros(y.shape[0])\n",
        "        result_solutions = y.new_zeros((y.shape[0], n_nonzero_coefs, 1))\n",
        "        original_indices = torch.arange(y.shape[0], dtype=sets.dtype, device=sets.device)\n",
        "\n",
        "    # Trade b*k^2+bk+bkM = O(bkM) memory for much less compute time. (This has to be done anyways since we are batching,\n",
        "    # otherwise one could just permute columns of X in-place as in https://github.com/scikit-learn/scikit-learn/blob/15a949460dbf19e5e196b8ef48f9712b72a3b3c3/sklearn/linear_model/_omp.py#L28 )\n",
        "    ATs = y.new_zeros(r.shape[0], n_nonzero_coefs, X.shape[0])\n",
        "    ATys = y.new_zeros(r.shape[0], n_nonzero_coefs, 1)\n",
        "    ATAs = torch.eye(n_nonzero_coefs, dtype=y.dtype, device=y.device)[None].repeat(r.shape[0], 1, 1)\n",
        "    if on_cpu:\n",
        "        # For CPU it is faster to use a packed representation of the lower triangle in ATA.\n",
        "        tri_idx = torch.tril_indices(n_nonzero_coefs, n_nonzero_coefs, device=sets.device, dtype=sets.dtype)\n",
        "        ATAs = ATAs[:, tri_idx[0], tri_idx[1]]\n",
        "\n",
        "    solutions = y.new_zeros((r.shape[0], 0))\n",
        "\n",
        "    for k in range(n_nonzero_coefs+bool(tol)):\n",
        "        # STOPPING CRITERIA\n",
        "        if tol:\n",
        "            problems_done = innerp(r) <= tol\n",
        "            if k == n_nonzero_coefs:\n",
        "                problems_done[:] = True\n",
        "\n",
        "            if problems_done.any():\n",
        "                remaining = ~problems_done\n",
        "\n",
        "                orig_idxs = original_indices[problems_done]\n",
        "                result_sets[orig_idxs, :k] = sets[problems_done, :k]\n",
        "                result_solutions[orig_idxs, :k] = solutions[problems_done]\n",
        "                result_lengths[orig_idxs] = k\n",
        "                original_indices = original_indices[remaining]\n",
        "\n",
        "                # original_indices = original_indices[remaining]\n",
        "                ATs = ATs[remaining]\n",
        "                ATys = ATys[remaining]\n",
        "                ATAs = ATAs[remaining]\n",
        "                sets = sets[remaining]\n",
        "                y = y[remaining]\n",
        "                r = r[remaining]\n",
        "                if problems_done.all():\n",
        "                    return result_sets, result_solutions, result_lengths\n",
        "        # GET PROJECTIONS AND INDICES TO ADD\n",
        "        if on_cpu:\n",
        "            projections = batch_mm(XT.numpy(), r[:, :, None].numpy())\n",
        "            argmax_blast(projections.squeeze(-1), sets[:, k].numpy())\n",
        "        else:\n",
        "            projections = XT @ r[:, :, None]\n",
        "            sets[:, k] = projections.abs().sum(-1).argmax(-1)  # Sum is just a squeeze, but would be relevant in SOMP.\n",
        "\n",
        "        # UPDATE AT\n",
        "        AT = ATs[:, :k + 1, :]\n",
        "        updateA = XT[sets[:, k], :]\n",
        "        AT[:, k, :] = updateA\n",
        "\n",
        "        # UPDATE ATy based on AT\n",
        "        ATy = ATys[:, :k + 1]\n",
        "        innerp(updateA, y, out=ATy[:, k, 0])\n",
        "\n",
        "        # UPDATE ATA based on AT or precomputed XTX.\n",
        "        if on_cpu:\n",
        "            packed_idx = k * (k - 1) // 2\n",
        "            if XTX is not None:  # Update based on precomputed XTX.\n",
        "                ATAs.t()[k + packed_idx:packed_idx + 2 * k + 1, :].t().numpy()[:] = XTX[sets[:, k, None], sets[:, :k + 1]]\n",
        "            else:\n",
        "                np.matmul(AT[:, :k + 1, :].numpy(), updateA[:, :, None].numpy(),\n",
        "                          out=ATAs.t()[k + packed_idx:packed_idx + 2 * k + 1, :].t()[:, :, None].numpy())\n",
        "        else:\n",
        "            ATA = ATAs[:, :k + 1, :k + 1]\n",
        "            if XTX is not None:\n",
        "                ATA[:, k, :k + 1] = XTX[sets[:, k, None], sets[:, :k + 1]]\n",
        "            else:\n",
        "                # Update ATAs by adding the new column of inner products.\n",
        "                torch.bmm(AT[:, :k + 1, :], updateA[:, :, None], out=ATA[:, k, :k + 1, None])\n",
        "\n",
        "        # SOLVE ATAx = ATy.\n",
        "        if on_cpu:\n",
        "            solutions = ATy.permute(0, 2, 1).clone().permute(0, 2, 1)  # Get a copy.\n",
        "            ppsv(ATAs.t()[:packed_idx + 2 * k + 1, :].t().contiguous().numpy(), solutions.numpy())\n",
        "        else:\n",
        "            ATA[:, :k, k] = ATA[:, k, :k]  # Copy lower triangle to upper triangle.\n",
        "            solutions = cholesky_solve(ATA, ATy)\n",
        "\n",
        "        # FINALLY, GET NEW RESIDUAL r=y-Ax\n",
        "        if on_cpu:\n",
        "            np.subtract(y.numpy(), (AT.permute(0, 2, 1).numpy() @ solutions.numpy()).squeeze(-1), out=r.numpy())\n",
        "        else:\n",
        "            torch.baddbmm(y[:, :, None], AT.permute(0, 2, 1), solutions, beta=-1, out=r[:, :, None])\n",
        "\n",
        "    return sets, solutions, None\n",
        "\n",
        "def omp_v0(X, y, XTX, n_nonzero_coefs=None, tol=None, inverse_cholesky=True):\n",
        "    B = y.shape[0]\n",
        "    normr2 = innerp(y)  # Norm squared of residual.\n",
        "    projections = (X.transpose(1, 0) @ y[:, :, None]).squeeze(-1)\n",
        "    sets = y.new_zeros(n_nonzero_coefs, B, dtype=torch.int64)\n",
        "\n",
        "    if inverse_cholesky:\n",
        "        # Doing the inverse-cholesky iteratively uses more memory,\n",
        "        # but takes less time than waiting till solving the problem in the end it seems.\n",
        "        # (Since F is triangular it could be __even faster__ to multiply, prob. not on GPU tho.)\n",
        "        F = torch.eye(n_nonzero_coefs, dtype=y.dtype, device=y.device).repeat(B, 1, 1)\n",
        "        a_F = y.new_zeros(n_nonzero_coefs, B, 1)\n",
        "\n",
        "    D_mybest = y.new_empty(B, n_nonzero_coefs, XTX.shape[0])\n",
        "    temp_F_k_k = y.new_ones((B, 1))\n",
        "\n",
        "    if tol:\n",
        "        result_lengths = sets.new_zeros(y.shape[0])\n",
        "        result_solutions = y.new_zeros((y.shape[0], n_nonzero_coefs, 1))\n",
        "        finished_problems = sets.new_zeros(y.shape[0], dtype=torch.bool)\n",
        "\n",
        "    for k in range(n_nonzero_coefs+bool(tol)):\n",
        "        # STOPPING CRITERIA\n",
        "        if tol:\n",
        "            problems_done = normr2 <= tol\n",
        "            if k == n_nonzero_coefs:\n",
        "                problems_done[:] = True\n",
        "\n",
        "            if problems_done.any():\n",
        "                new_problems_done = problems_done & ~finished_problems\n",
        "                finished_problems.logical_or_(problems_done)\n",
        "                result_lengths[new_problems_done] = k\n",
        "                if inverse_cholesky:\n",
        "                    result_solutions[new_problems_done, :k] = F[new_problems_done, :k, :k].permute(0, 2, 1) @ a_F[:k, new_problems_done].permute(1, 0, 2)\n",
        "                else:\n",
        "                    assert False, \"inverse_cholesky=False with tol != None is not handled yet\"\n",
        "                if problems_done.all():\n",
        "                    return sets.t(), result_solutions, result_lengths\n",
        "\n",
        "        sets[k] = projections.abs().argmax(1)\n",
        "        # D_mybest[:, k, :] = XTX[gamma[k], :]  # Same line as below, but significantly slower. (prob. due to the intermediate array creation)\n",
        "        torch.gather(XTX, 0, sets[k, :, None].expand(-1, XTX.shape[1]), out=D_mybest[:, k, :])\n",
        "        if k:\n",
        "            D_mybest_maxindices = D_mybest.permute(0, 2, 1)[torch.arange(D_mybest.shape[0], dtype=sets.dtype, device=sets.device), sets[k], :k]\n",
        "            torch.rsqrt(1 - innerp(D_mybest_maxindices),\n",
        "                        out=temp_F_k_k[:, 0])  # torch.exp(-1/2 * torch.log1p(-inp), temp_F_k_k[:, 0])\n",
        "            D_mybest_maxindices *= -temp_F_k_k  # minimal operations, exploit linearity\n",
        "            D_mybest[:, k, :] *= temp_F_k_k\n",
        "            D_mybest[:, k, :, None].baddbmm_(D_mybest[:, :k, :].permute(0, 2, 1), D_mybest_maxindices[:, :, None])\n",
        "\n",
        "\n",
        "        temp_a_F = temp_F_k_k * torch.gather(projections, 1, sets[k, :, None])\n",
        "        normr2 -= (temp_a_F * temp_a_F).squeeze(-1)\n",
        "        projections -= temp_a_F * D_mybest[:, k, :]\n",
        "        if inverse_cholesky:\n",
        "            a_F[k] = temp_a_F\n",
        "            if k:  # Could maybe get a speedup from triangular mat mul kernel.\n",
        "                torch.bmm(D_mybest_maxindices[:, None, :], F[:, :k, :], out=F[:, k, None, :])\n",
        "                F[:, k, k] = temp_F_k_k[..., 0]\n",
        "    else: # FIXME: else branch will not execute if n_nonzero_coefs=0, so solutions is undefined.\n",
        "        # Normal exit, used when tolerance=None.\n",
        "        if inverse_cholesky:\n",
        "            solutions = F.permute(0, 2, 1) @ a_F.squeeze(-1).transpose(1, 0)[:, :, None]\n",
        "        else:\n",
        "            # Solving the problem in the end without using inverse Cholesky.\n",
        "            AT = X.T[sets.T]\n",
        "            solutions = cholesky_solve(AT @ AT.permute(0, 2, 1), AT @ y.T[:, :, None])\n",
        "\n",
        "    return sets.t(), solutions, None"
      ],
      "metadata": {
        "id": "OICbLfF3U9DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse Keys & Values Analysis"
      ],
      "metadata": {
        "id": "eLUNRV7HDdBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import loadtxt\n",
        "from transformers import GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "KEYS_VALUES_PATH = \"./gpt2_omp_results/\"\n",
        "layer_num = 0\n",
        "\n",
        "gpt2_analysis = GPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128)\n",
        "gpt2_analysis.load_state_dict(torch.load(STATE_FILE_DIR+\"gpt2_state_w_finetuning.pt\"))\n",
        "\n",
        "gpt2_analysis_st = gpt2_analysis.gpt2model.state_dict() # model state dictionary\n",
        "keys = gpt2_analysis_st[f\"h.{layer_num}.mlp.c_fc.weight\"].detach().to(device)\n",
        "values = gpt2_analysis_st[f\"h.{layer_num}.mlp.c_proj.weight\"].detach().to(device)\n",
        "\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "print(f\"Results for GPT2 - Layer {layer_num} - Without Sparsity\")\n",
        "print(f\"-----------------------------------------\")\n",
        "\n",
        "for i in range(100):\n",
        "  sorted_keys, indices_keys = torch.sort(torch.abs(keys[i]), descending=True)\n",
        "  print(\"Key: \", gpt2_tokenizer.batch_decode(indices_keys[0:10]))\n",
        "\n",
        "  sorted_values, indices_values = torch.sort(torch.abs(values[i]), descending=True)\n",
        "  print(\"Value: \", gpt2_tokenizer.batch_decode(indices_values[0:10]))\n",
        "  print(\"#################################################\")"
      ],
      "metadata": {
        "id": "IhfcqoX8Nmi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "930bb988-f10c-4309-9cf1-cf3635f2d250"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for GPT2 - Layer 0 - Without Sparsity\n",
            "-----------------------------------------\n",
            "Key:  ['�', ' hum', 'idence', '01', ' user', ' space', ' kn', ' am', 'the', ' country']\n",
            "Value:  [' time', '�', \"'\", ' In', '�', '\\r', '_', ' w', ' or', ' also']\n",
            "#################################################\n",
            "Key:  [' sim', 'ead', ' commun', ' mean', 'arn', 'orld', 'ote', 'ising', ' boy', ' Euro']\n",
            "Value:  ['rom', ' there', '~', 'ject', '�', ' rec', 'iv', ' just', '�', ' back']\n",
            "#################################################\n",
            "Key:  [' been', 'amer', ' foot', 'ally', ' mean', 'ches', 'iol', ' rad', 'osing', 'ters']\n",
            "Value:  ['�', \"'t\", 'ents', '�', 'age', '01', 'ld', '\\x05', ' new', '�']\n",
            "#################################################\n",
            "Key:  ['ches', ' sw', 'OM', ' drug', ' old', 'ics', 'aint', '�', 'ulation', ' started']\n",
            "Value:  [' may', '>', ' comp', '�', ' st', ' It', 'ay', ' fe', 's', 'ub']\n",
            "#################################################\n",
            "Key:  ['aid', ' mem', 'ible', 'eng', '#', ' inst', ' sim', ' ill', 'als', ' char']\n",
            "Value:  ['�', 'ce', '�', 'ime', ' my', ' ad', ' F', ' al', ' some', ' n']\n",
            "#################################################\n",
            "Key:  ['�', ' collect', '<', ' struct', ' sit', ' non', 'ood', ' He', ' Car', 'ull']\n",
            "Value:  [' him', 'ors', '�', '�', 'ill', 'c', ' Y', '�', 'z', ' o']\n",
            "#################################################\n",
            "Key:  [' targ', 'iven', 'thing', ' key', ' bit', ' terms', 'ines', ' agre', ' educ', ' tri']\n",
            "Value:  ['�', 'ous', 'if', '�', '�', ' was', 'ress', ' fe', 'og', ' and']\n",
            "#################################################\n",
            "Key:  [' <', ' and', 'ost', ' higher', ' States', 'ational', ' manag', 'ides', ' soon', '70']\n",
            "Value:  [' was', '�', 'cl', 'ac', ' get', 'k', ' spe', ' The', 'og', 'ect']\n",
            "#################################################\n",
            "Key:  ['ising', 'irm', ' terms', 'ally', ' issues', ' a', 'When', 'IS', 'lic', ' educ']\n",
            "Value:  ['�', ' after', ' rec', ' sc', 'ens', ' re', ' sa', 'ay', ' out', ' they']\n",
            "#################################################\n",
            "Key:  [' energy', ' political', 'mm', 'ublic', ' Brit', 'ript', '�', ' happen', 'ream', 'one']\n",
            "Value:  ['�', '\\x17', ' most', ' H', ' we', ' go', '�', ' also', 'ov', ' cl']\n",
            "#################################################\n",
            "Key:  [' US', 'amer', 'orld', 'When', ' girl', ' already', 'b', 'hold', ' issues', ' story']\n",
            "Value:  [' or', 'ost', 'ber', '�', ' there', 'urn', 'ot', '�', 'ual', '�']\n",
            "#################################################\n",
            "Key:  [' accept', 'che', ' sim', ' include', 'ible', 'te', ' John', ' er', ' few', 'ause']\n",
            "Value:  ['�', 'a', ' was', 'ence', 'ink', ' s', 'k', ' all', 'iv', '�']\n",
            "#################################################\n",
            "Key:  ['OM', 'H', ' Sh', '�', 'ink', ' countries', '�', ' Google', ' accept', '07']\n",
            "Value:  ['�', ' ad', 'us', '\\x11', ' has', ' su', ' wor', 'il', 'om', ' 4']\n",
            "#################################################\n",
            "Key:  [' say', 'igh', ' decision', 'ric', ' city', '�', ' school', '�', 'ien', 'ible']\n",
            "Value:  ['ove', ' into', ' j', '\\x10', 've', 'ck', 'ill', '~', ' may', '�']\n",
            "#################################################\n",
            "Key:  ['ens', 'ceed', 'art', ' sens', ' dev', ' risk', 'aign', ' hum', 'ater', ' av']\n",
            "Value:  [' o', '\\x14', 'A', '�', 'ud', 'oy', 'ious', ' my', ' fe', '�']\n",
            "#################################################\n",
            "Key:  ['orld', '�', ' able', ' great', ' pict', 'oe', 'ote', ' already', 'apan', ' girl']\n",
            "Value:  ['�', '\\x14', ' E', '�', '.\"', '\\x1a', ' f', 'ook', 'itt', '�']\n",
            "#################################################\n",
            "Key:  [' l', '08', 'the', 'reat', ' hum', 'omb', ' Gener', ' yet', ' <', '�']\n",
            "Value:  [',\"', ' time', 'ach', 'es', 'ay', 'our', 'ian', ' n', ' b', '�']\n",
            "#################################################\n",
            "Key:  [' war', '{', '+', ' Pro', '�', ' av', 'ton', 'icle', ' author', 'ert']\n",
            "Value:  [' The', 'ople', 'ri', '>', ' some', 'ome', '\\x18', '�', ' I', \"'s\"]\n",
            "#################################################\n",
            "Key:  [' W', ' crit', 'ret', 'ex', 'omet', ' country', '23', ' pot', '5', ' am']\n",
            "Value:  ['�', '\\x14', 'ir', '\\x07', ' h', '�', 'ates', ' G', 'ook', 'ry']\n",
            "#################################################\n",
            "Key:  [' mean', 'ane', ' l', ' space', 'amer', 'W', 're', 'unk', 'ches', ' polit']\n",
            "Value:  ['@', '�', 're', '�', ' my', '�', '�', 'ion', ' want', ' cons']\n",
            "#################################################\n",
            "Key:  ['ION', 'ration', ' more', '3', ' person', 'action', '�', 'ru', 'pp', ' police']\n",
            "Value:  ['�', '�', ' en', '$', ' st', '\\x0e', ' wor', ' is', 'ance', '�']\n",
            "#################################################\n",
            "Key:  [' called', ' issues', ' questions', ' started', 'omb', ' dead', 'oci', ' 7', '�', '\\x0b']\n",
            "Value:  ['�', '�', ' K', '�', '�', '�', 'st', '�', ' S', 'er']\n",
            "#################################################\n",
            "Key:  ['gin', ' Red', 'ari', ' pick', ' r', ' act', 'ged', 'H', ' individual', 'ife']\n",
            "Value:  ['ook', ' my', 'ment', '1', ' ex', ' its', ' sc', ' im', 're', '�']\n",
            "#################################################\n",
            "Key:  [' mean', ' all', ' three', 'reat', 'When', ' national', ' family', 'ient', ' cond', 'iven']\n",
            "Value:  ['ov', 'her', 'ent', 'e', ' over', 'ol', ' St', 'ost', 'oll', 'itt']\n",
            "#################################################\n",
            "Key:  [' dev', 'st', ' enjoy', ' appear', 'They', 'iness', ' Bro', 'ered', ' right', ' Mich']\n",
            "Value:  ['/', ' f', 'nt', ' it', 'ans', ' ha', '\\x1f', '�', 'rou', '\\x18']\n",
            "#################################################\n",
            "Key:  [' current', 'we', 'ety', 'eter', ' most', 'ream', ' Department', 'é', 'mber', ' anim']\n",
            "Value:  [' them', '�', ' rec', ' ', ' get', ' he', 'ist', 'ib', '�', 'Z']\n",
            "#################################################\n",
            "Key:  ['iven', ' gun', 'When', ' arri', ' mean', ' seems', '17', ' targ', \"'ve\", '�']\n",
            "Value:  ['�', 'ite', ' He', 'ub', '�', 'ick', '�', ' was', ' F', '\\\\']\n",
            "#################################################\n",
            "Key:  ['son', ' imp', ' comp', 'eng', ' front', ' reve', ' success', ' block', 'ci', ' ex']\n",
            "Value:  ['ign', ' ad', '�', '�', '�', 'ru', '�', ' He', ' 201', '�']\n",
            "#################################################\n",
            "Key:  ['als', 'ization', 'ills', ' Google', ' Com', ' crit', 'yn', 'aring', ' result', ' front']\n",
            "Value:  ['an', 'ud', ' in', ' n', ' again', ' is', 'll', '#', 'ne', '\\r']\n",
            "#################################################\n",
            "Key:  [' polic', '�', 'gg', ' step', '60', ' cou', 'lic', ' Eng', ' But', ' model']\n",
            "Value:  ['�', 'ent', '--', 'ents', 'in', '�', 'ist', 'L', '�', '\\x1a']\n",
            "#################################################\n",
            "Key:  ['ream', 'rel', 'ety', 'ited', 'ches', '...', ' —', ' Par', ' base', ' played']\n",
            "Value:  ['�', ' P', ' I', 'N', ' ch', ' comm', 'ust', ' cl', '�', '�']\n",
            "#################################################\n",
            "Key:  [' A', ' book', ' ro', ' more', '...', ' land', ' last', ' body', 'alth', '----------------']\n",
            "Value:  ['�', '�', 'one', '\\n', 'ol', 'se', 'ord', 'ident', '\\x0f', ').']\n",
            "#################################################\n",
            "Key:  [' dom', 'ublic', ' A', 'raft', ' sold', 'ctions', 'son', ' only', 'now', ' year']\n",
            "Value:  ['\\x05', 'ict', 'ther', ' not', '�', 'ike', '2', 'amp', 'od', 'd']\n",
            "#################################################\n",
            "Key:  [' war', 'rug', 'ven', '----', '�', ' tou', 'che', ' relations', ' anything', 'ause']\n",
            "Value:  ['\\x07', '\\x1c', 'Z', '!', ' new', ' or', '_', ' me', ' He', 'm']\n",
            "#################################################\n",
            "Key:  [' mother', 'irm', 'ert', 'ising', ' Com', 'IS', ' sim', 'ideo', ' stop', ' follow']\n",
            "Value:  ['ach', 'ill', 'ent', 'ut', ' k', 's', 'ell', 'ove', ' S', '�']\n",
            "#################################################\n",
            "Key:  ['reen', ' user', 'ric', '}', '01', 'emy', '11', ' wom', ' parent', ' probably']\n",
            "Value:  ['el', ' am', ' under', 'pp', 'vel', '�', ' would', 'N', ' res', '\\x18']\n",
            "#################################################\n",
            "Key:  [' mean', ' partic', ' manag', 'ires', 'Th', 'du', 'fter', ' :', '01', ' ad']\n",
            "Value:  ['ull', ' kn', ' bec', ' im', ' them', 'll', ' so', '�', 'ag', ' D']\n",
            "#################################################\n",
            "Key:  ['60', 'mer', 'ited', ' once', ' more', ' protect', '.\"', ' veh', ' so', ' Now']\n",
            "Value:  [' that', ' or', ' will', ' was', ' w', 'ich', ' $', 'a', \"'\", ' qu']\n",
            "#################################################\n",
            "Key:  ['�', 'ague', ' ex', 'ization', ' sit', ' short', ' applic', 'ting', '//', '�']\n",
            "Value:  ['�', ' S', ' for', '�', ',', ' m', ' ', '^', ' just', 'ime']\n",
            "#################################################\n",
            "Key:  [' perform', ' An', 'ict', '�', ' K', 'igh', ' step', '�', ' fac', ' crit']\n",
            "Value:  ['�', '~', 'du', 'ess', 'ri', 'P', 'ate', 'ome', 'ven', 'fter']\n",
            "#################################################\n",
            "Key:  ['�', ' But', ' item', ' sa', ' article', 'ful', '\\x0c', 'IN', ' Eng', '28']\n",
            "Value:  ['cl', ',\"', 'N', 'all', ' part', ' do', 'C', 'fore', 'th', ' I']\n",
            "#################################################\n",
            "Key:  ['�', 'oul', 'med', 'imes', 'aid', ' above', 'umb', '�', ' it', ' block']\n",
            "Value:  ['�', '\\x13', 'ian', ' o', ' P', 'it', 'us', '\\x03', 'A', 'ally']\n",
            "#################################################\n",
            "Key:  [' however', 'ertain', 'isk', ' r', 'old', ' mil', ' enjoy', ' sm', ' veh', '�']\n",
            "Value:  [' time', '�', ' o', ' after', 'ber', '.\"', ' He', '�', 'ph', 'ov']\n",
            "#################################################\n",
            "Key:  [' sub', ' South', 'med', 'aid', 'min', 'ague', ' mother', ' University', ' rese', 'ech']\n",
            "Value:  ['�', ' was', ' get', '�', '�', 'ity', 'd', ' tr', ' or', ' w']\n",
            "#################################################\n",
            "Key:  [' national', ' Oct', 'iven', ' Dav', '01', '�', 'ili', 'When', ' hum', '49']\n",
            "Value:  ['x', ' w', ' d', '�', '�', ' 6', ' time', '�', ' work', 'The']\n",
            "#################################################\n",
            "Key:  [' decided', 'ute', ' again', 'lev', ' z', ' commun', ' story', ' gu', 'ends', ' crit']\n",
            "Value:  [' time', 'ition', '@', '�', 'ge', '�', 'ock', '�', ' an', ' need']\n",
            "#################################################\n",
            "Key:  [' along', ' sec', ' sold', ' applic', ' rest', ' rec', 'iver', ' role', ' supp', ' fem']\n",
            "Value:  ['A', 'age', '�', '5', ' most', 'ock', '\\x0f', 'we', '01', ' -']\n",
            "#################################################\n",
            "Key:  ['oto', 'med', '�', ' bec', ' collect', ' reve', 'atic', 'our', ' option', ' P']\n",
            "Value:  [' get', '�', '\\\\', '�', '\\x11', ' (', '<', 'ood', 'il', 'ct']\n",
            "#################################################\n",
            "Key:  [' targ', ' educ', ' Con', ' late', ' mus', 'du', ' Americ', 'iven', 'So', ' saying']\n",
            "Value:  ['st', 'we', 'ust', '--', 'N', '�', '�', 'ib', 'ice', '@']\n",
            "#################################################\n",
            "Key:  [' mean', 'ances', 'W', 'une', ' partic', ' less', 'play', ' seem', ' profess', 'ts']\n",
            "Value:  [' time', 'ber', '�', '�', ' new', '�', '!', ' h', '�', 'od']\n",
            "#################################################\n",
            "Key:  [' But', ' only', ' type', 'ional', '\\x0c', ' second', 'um', 'ertain', '21', ' ter']\n",
            "Value:  ['our', 'ens', ' spe', '�', ' com', '�', 'um', 'ull', 'her', 'du']\n",
            "#################################################\n",
            "Key:  ['ath', ' Google', '�', 'ret', ' State', 'Tr', 'rim', ' l', ' once', ' num']\n",
            "Value:  [' app', ' d', ' not', 'us', '�', 'ite', 'ice', '�', '�', '�']\n",
            "#################################################\n",
            "Key:  [' mean', 'When', ' dev', 'du', ' two', ' except', 'unk', 'ile', 'ging', 'ie']\n",
            "Value:  ['D', 'Z', ' d', 'Q', 'er', ' Y', 'd', ' 1', 'ut', 'm']\n",
            "#################################################\n",
            "Key:  [' called', ' once', ' E', ' right', ' Google', ' at', '�', 'ples', ' But', '====']\n",
            "Value:  ['�', '�', 'ch', ').', 'her', '�', ' you', '�', 'ans', 'st']\n",
            "#################################################\n",
            "Key:  [' l', ' vict', 'hed', ' risk', 'ric', ' home', 'iven', 'or', ' sm', ' cle']\n",
            "Value:  ['O', '\\x0f', '�', '�', ' by', ').', ' I', 'ater', ' or', ' spe']\n",
            "#################################################\n",
            "Key:  [' partic', 'play', 'ality', 'idence', ' track', ' vict', 'ances', ' differe', ' training', 'ote']\n",
            "Value:  ['ens', 'reat', '�', '�', ' at', 'er', '}', ' int', 'ith', 'ord']\n",
            "#################################################\n",
            "Key:  ['=', ' war', '�', ' 100', ' whole', ' weap', ' impact', '36', 'ream', 'ru']\n",
            "Value:  [' Ch', '\\x19', ' ad', 'ual', ' time', '3', ' co', '�', ' Th', 'est']\n",
            "#################################################\n",
            "Key:  ['idence', '�', ' dev', ' vict', ' G', 'When', 'amer', ' These', 'aign', '60']\n",
            "Value:  [' him', ' under', 'ic', '�', 'ie', 'E', 'ause', ' may', ' tw', ' other']\n",
            "#################################################\n",
            "Key:  [' issues', ' Post', ' v', ' sens', 'ite', ' someone', 'ature', ' eff', 'ute', 'est']\n",
            "Value:  ['�', ' was', ' want', ' le', 'ment', ' time', '�', 'z', ' Ch', 'per']\n",
            "#################################################\n",
            "Key:  ['ally', ' 17', ' Jan', '�', ' section', ' ins', ' est', '01', 'uck', ' might']\n",
            "Value:  ['ere', ' get', ' sh', ' was', 'D', 'av', 'ity', '\\x17', 'ors', ' pol']\n",
            "#################################################\n",
            "Key:  [' foot', 'IS', ' These', ' Cour', 'or', 'ising', ' Comm', 'irm', ' l', 'ary']\n",
            "Value:  ['ach', ' his', 'ther', ' pro', '\\x07', ' U', 'ally', ' b', '\"', ' is']\n",
            "#################################################\n",
            "Key:  ['atic', '�', 'ceed', ' bu', ' weap', ' school', '32', ' anything', 'ument', ' enjoy']\n",
            "Value:  ['w', ' my', '\\x04', ' out', ' new', 'm', '�', 'p', 'ase', 'ul']\n",
            "#################################################\n",
            "Key:  [' Bl', ' Sw', 'reen', ' following', 'du', '�', 'une', ' after', '!', ' ins']\n",
            "Value:  ['ook', ' new', '{', 'ec', '�', ' but', '�', ' cont', 'amp', \"'t\"]\n",
            "#################################################\n",
            "Key:  ['ane', 'du', 'ile', ' order', '{', ' Will', ' able', ' vict', ' hum', 'ud']\n",
            "Value:  ['?', 'n', ' W', 'ity', ' into', '\\x15', ' need', 'rou', '�', 'ree']\n",
            "#################################################\n",
            "Key:  [' by', ' Al', 'uch', 'aim', ' family', 'ality', 'ances', ' ord', 'ute', ' called']\n",
            "Value:  [' bec', '\\t', 'V', ' year', 'pt', ' us', 'ens', '�', '%', ' r']\n",
            "#################################################\n",
            "Key:  ['\\x1c', ' nearly', ' control', 'ublic', 'oy', ' Dep', '60', '27', ' ter', ' dom']\n",
            "Value:  [' get', ' new', ' S', '\\x11', '�', '{', '�', 've', 'ke', ' ro']\n",
            "#################################################\n",
            "Key:  [' United', '27', 'ones', 'ration', ' read', ' p', 'ague', ' 9', 'ills', '8']\n",
            "Value:  ['erv', ' de', '�', '2', 'ud', 'itt', ' ad', 'ance', 'age', 'ase']\n",
            "#################################################\n",
            "Key:  [' mean', ' space', ' exec', ' South', ' girl', 'ud', ' accept', '�', ' a', 'idence']\n",
            "Value:  ['us', ' or', ' was', 'a', ' time', ' V', 'iz', '\\x1c', 'ove', 'ph']\n",
            "#################################################\n",
            "Key:  [' ann', ' war', ' US', '�', 'oe', 'ral', ' am', 'ories', ' vict', ' dev']\n",
            "Value:  ['U', '\\x0e', '�', 'ep', 'ther', ' off', 'nder', '�', ' be', 'st']\n",
            "#################################################\n",
            "Key:  [' Car', 'we', 'uly', 'med', 'ches', 'use', ' act', 'aving', '�', 'ual']\n",
            "Value:  [' he', 'ove', ' has', '\\r', 'reat', 'ould', ' them', '�', 'ind', 'ere']\n",
            "#################################################\n",
            "Key:  [' country', 'or', 'sw', ' however', ' conf', 'lic', 'ili', 'hold', 'gg', ' understand']\n",
            "Value:  ['ction', '�', '�', '�', 'e', ' time', ' be', 'pp', 'ents', 'ike']\n",
            "#################################################\n",
            "Key:  ['ires', ' day', 'ree', ' soon', ' effects', 'ification', ' member', ' ord', 'ious', ' Med']\n",
            "Value:  [' de', 'port', ' would', '-', ' some', 'ign', ' 3', 'ick', '9', '�']\n",
            "#################################################\n",
            "Key:  ['gg', ' question', ' Russ', '//', ' happen', 'vious', ' man', ' available', '�', 'ide']\n",
            "Value:  ['x', 'ame', 'ast', ' w', ' 5', 'ont', 'h', 'oc', ' ne', 'a']\n",
            "#################################################\n",
            "Key:  ['rough', ' former', ' questions', 'aging', ' bec', ' applic', ' where', ' lead', ' produ', ' pay']\n",
            "Value:  ['�', ' out', '\\x1b', ' N', ' fe', '�', 'or', ' am', '\\x19', '�']\n",
            "#################################################\n",
            "Key:  ['<', 'alf', 'and', 'ited', 'orn', ' def', 'ertain', 'j', '44', ' typ']\n",
            "Value:  ['ne', '�', ' I', ' see', '5', ' my', 'ok', '�', 'it', 'i']\n",
            "#################################################\n",
            "Key:  [' mean', 'obal', 'W', ' mass', ' mother', 'oes', ' dis', 'res', ' force', ' vict']\n",
            "Value:  ['�', 'ch', '�', '�', ' (', ' who', 'ity', ' do', ' them', 'nder']\n",
            "#################################################\n",
            "Key:  [' year', ' school', ' sens', '49', 'ful', 'am', ' ann', ' rese', ' called', ' may']\n",
            "Value:  ['%', ' need', ' about', ' g', '�', '�', ' un', '�', ' bl', 'ase']\n",
            "#################################################\n",
            "Key:  ['rown', ' seems', 'ata', '49', 'V', 'du', ' creat', 'iven', ' found', ' individual']\n",
            "Value:  ['rough', '�', 'ge', 'ac', 'ag', 'ign', ' de', '..', '[', '-']\n",
            "#################################################\n",
            "Key:  ['When', ' looking', 'the', 'amer', ' hum', ' AM', ' cour', 'orld', 'ient', ' hit']\n",
            "Value:  ['st', '�', ' de', 'ia', 'art', ' th', 'out', '�', ' I', '\\x11']\n",
            "#################################################\n",
            "Key:  [' interview', ' front', ' hit', 'ink', ' Department', ' again', 'ook', 'ict', ' cou', 'land']\n",
            "Value:  [' people', ' be', 'pl', 'cc', '�', '�', 'ide', 'un', 'ri', ' so']\n",
            "#################################################\n",
            "Key:  [' saying', ' sim', 'So', ' girl', ' might', '49', ' conf', 'ard', '40', 'idence']\n",
            "Value:  ['�', 'art', 'ff', '/', ' ad', '�', \"'s\", 'ach', 'ance', ' act']\n",
            "#################################################\n",
            "Key:  ['use', ' Car', ' anything', '�', ' indic', 'uc', 'ide', '36', 'son', ' free']\n",
            "Value:  [' In', '�', ' d', ' was', '\\x19', ' or', ' also', '�', '�', 'ont']\n",
            "#################################################\n",
            "Key:  ['ety', ' mass', ' fund', 'How', ' single', '�', ' control', ' text', ' block', ' have']\n",
            "Value:  ['ook', 'ens', '�', '\\x1a', '\\x0b', '�', 'R', '�', 'am', ' cl']\n",
            "#################################################\n",
            "Key:  [' contin', ' individual', ' sim', 'rown', 'When', '\\r', ' Post', ' coun', '23', ' should']\n",
            "Value:  ['ose', '/', ']', ' people', ' go', ' h', ' P', ' again', '----', 'ib']\n",
            "#################################################\n",
            "Key:  ['There', ' inter', 'ered', 'dd', ' held', '...', ' might', ' enjoy', ' 100', 'ier']\n",
            "Value:  ['�', '�', '�', '?', '�', 'ck', 'K', 'us', ' so', 'qu']\n",
            "#################################################\n",
            "Key:  ['When', 'ment', 'emy', 'uck', ' profess', ' early', ' G', 'ized', ' ad', 'ines']\n",
            "Value:  ['itt', 'ase', '�', 'od', 'ies', ' The', ' know', '�', 'ans', 'art']\n",
            "#################################################\n",
            "Key:  ['une', 'ens', 'aut', 'ways', ' soc', 'reme', 'ox', 'ality', 'idence', 'ally']\n",
            "Value:  [' would', 'ally', 'ign', 'ec', 'very', ' of', 'ove', ' Ch', 'ne', '�']\n",
            "#################################################\n",
            "Key:  ['ume', 'ires', ' next', 'atter', '70', ' target', ' wom', 'uch', ' Med', 'ough']\n",
            "Value:  [' people', ' than', ' L', 'ach', '�', '�', 'are', '�', 'ces', 'ction']\n",
            "#################################################\n",
            "Key:  ['�', ' regard', 'om', ' were', ' occ', ' init', '28', 'ink', ' veh', 'ect']\n",
            "Value:  ['clud', '�', '.', ' time', '�', '\\x17', ' under', '<', ' his', '�']\n",
            "#################################################\n",
            "Key:  [' held', 'ally', '40', 'or', ' issues', ' US', ' block', ' good', 'When', 'for']\n",
            "Value:  ['.\"', '�', ' [', '�', ' or', '\\\\', ' He', '\\x1c', ' h', '�']\n",
            "#################################################\n",
            "Key:  ['�', ' final', '�', ' at', ' prim', 'OM', 'eter', 'op', ' sec', 'W']\n",
            "Value:  ['\\x1a', 'ings', ' my', ' V', ' en', 'ord', 'orm', \"'s\", '�', ' to']\n",
            "#################################################\n",
            "Key:  ['ors', ' le', '�', 'med', 'vironment', 'oul', 'use', 'G', ' Google', ' civil']\n",
            "Value:  ['\\x18', ' was', '%', 'urn', '�', '>', 'et', ' year', ' co', 'her']\n",
            "#################################################\n",
            "Key:  ['+', 'er', 'ety', ' stay', ' protect', '�', 'med', 'oul', ' 3', ' it']\n",
            "Value:  ['�', 'ign', ' was', ' out', ' play', ' H', ' or', '!', '�', 'E']\n",
            "#################################################\n",
            "Key:  [' companies', 'stem', ' talk', 'ass', ' seen', ' dom', ' John', ' fav', ' Col', 'mit']\n",
            "Value:  [' was', ' w', 'ame', 'ick', '(', 'es', ' He', ' c', 'Q', 'ph']\n",
            "#################################################\n",
            "Key:  [' decided', ' min', ' fore', ' along', '//', 'clus', 'ined', ' 2014', ' feel', 'og']\n",
            "Value:  ['os', '�', 'art', 'og', 'ction', 'ap', 'ing', 'at', '�', 'th']\n",
            "#################################################\n",
            "Key:  [' war', '�', 'o', 'ces', ' available', '…', ' called', ' rese', ' material', ' private']\n",
            "Value:  ['�', 'ated', 'so', 'ust', 'itt', ' them', ' been', 'st', 'es', '\\x17']\n",
            "#################################################\n",
            "Key:  ['omet', ' land', ' campaign', ' inst', ' fe', ' isn', ' material', ' cou', 'Pro', '�']\n",
            "Value:  [' w', 'ame', 'x', 'a', '�', '�', '�', '\\x19', ' was', ' The']\n",
            "#################################################\n",
            "Key:  [' educ', 'iven', ' Con', ' gun', 'or', ' space', ' kn', ' effects', ' risk', 'use']\n",
            "Value:  ['ct', ' comp', 'her', 'ish', '�', 'gh', 'ual', '>', 'P', ' v']\n",
            "#################################################\n",
            "Key:  [' available', '�', ' single', ' av', 'ions', ' (', ' questions', ' entire', 'aving', 'ration']\n",
            "Value:  ['er', 'ub', '�', '\\x0f', ' was', 'ed', ' on', 'ull', 'ig', '6']\n",
            "#################################################\n",
            "Key:  [' quickly', ' mean', 'ved', ' <', 'ost', ' simple', 'r', '65', ' effects', '�']\n",
            "Value:  ['ov', 'ach', '\\x01', '/', 'ict', 'art', ' H', '�', ' there', '�']\n",
            "#################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import savetxt\n",
        "LAYER_NUM = 10\n",
        "\n",
        "# Load fine-tuned GPT2\n",
        "gpt2_analysis = GPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128)\n",
        "gpt2_analysis.load_state_dict(torch.load(STATE_FILE_DIR+\"gpt2_state_w_finetuning.pt\"))\n",
        "\n",
        "# for name,x in gpt2_analysis.named_parameters():\n",
        "   # if \"mlp.c_fc.weight\" in name: # c_fc is the feed forward part of the layer \n",
        "      # print(name)\n",
        "\n",
        "# Get embeddings and BERT state\n",
        "embeddings = gpt2_analysis.gpt2model.get_input_embeddings()\n",
        "E = embeddings.weight.detach().to(device)\n",
        "gpt2_analysis_st = gpt2_analysis.gpt2model.state_dict() # model state dictionary\n",
        "\n",
        "# Compute sparse keys\n",
        "keys = gpt2_analysis_st[f\"h.{LAYER_NUM}.mlp.c_fc.weight\"].detach().to(device)\n",
        "n_non_zero_keys = max(int(0.1 * keys.shape[0]), 1)\n",
        "sparse_keys = run_omp(E.T,  keys.T, n_non_zero_keys) # run optimized OMP\n",
        "savetxt(KEYS_VALUES_PATH+f\"layer{LAYER_NUM}_keys.csv\", sparse_keys, delimiter=',')\n",
        "\n",
        "# Compute sparse values\n",
        "values = gpt2_analysis_st[f\"h.{LAYER_NUM}.mlp.c_proj.weight\"].detach().to(device)\n",
        "n_non_zero_values = max(int(0.1 * values.shape[1]), 1)\n",
        "sparse_values = run_omp(E.T,  values.T, n_non_zero_values) # run optimized OMP\n",
        "savetxt(KEYS_VALUES_PATH+f\"layer{LAYER_NUM}_values.csv\", sparse_values, delimiter=',')"
      ],
      "metadata": {
        "id": "EwdZpgNjDYdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import loadtxt\n",
        "LAYER_NUM = 11\n",
        "\n",
        "sparse_keys = loadtxt(KEYS_VALUES_PATH+f\"layer{LAYER_NUM}_keys.csv\", delimiter=',').astype(\"double\")\n",
        "sparse_keys = torch.from_numpy(sparse_keys).to(device)\n",
        "sparse_values = loadtxt(KEYS_VALUES_PATH+f\"layer{LAYER_NUM}_values.csv\", delimiter=',').astype(\"double\")\n",
        "sparse_values = torch.from_numpy(sparse_values).to(device)"
      ],
      "metadata": {
        "id": "GsNy_mWHhJSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "i = 0\n",
        "\n",
        "for i in range(100):\n",
        "  # non_zero_keys = torch.nonzero(sparse_keys[i])\n",
        "  sorted_keys, indices_keys = torch.sort(torch.abs(sparse_keys[i]), descending=True)\n",
        "  print(tokenizer.batch_decode(indices_keys[0:10]))\n",
        "\n",
        "  # non_zero_values = torch.nonzero(sparse_values[i])\n",
        "  sorted_values, indices_values = torch.sort(torch.abs(sparse_values[i]), descending=True)\n",
        "  print(tokenizer.batch_decode(indices_values[0:10]))\n",
        "  # print(tokenizer.batch_decode(non_zero_values))\n",
        "  print(\"#################################################\")"
      ],
      "metadata": {
        "id": "JVyj6-hZn-N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show Relation in Histogram\n",
        "plt.bar(indices_keys[:76].cpu().numpy(),sorted_keys[:76].cpu().numpy(), width=indices_keys[:76].cpu()[1]-indices_keys[:76].cpu()[0], ec='k', lw=1)\n",
        "plt.ylim(0, max(sorted_keys[:76].cpu().numpy())*1.1)\n",
        "plt.bar(indices_values[:76].cpu().numpy(),sorted_values[:76].cpu().numpy(), width=indices_values[:76].cpu()[2]-indices_values[:76].cpu()[1], ec='k', lw=1, alpha=0.1)\n",
        "plt.ylim(0, max(sorted_values[:76].cpu().numpy())*1.1)\n",
        "\n",
        "# TODO: show relation in embedding space plot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wDC779X7LzkH",
        "outputId": "c7d677ff-6ff0-4357-b597-3f4e2138b710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0900326609611513)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "import torch.nn.functional as F\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "inputs = tokenizer(tokenizer.decode(indices_values[0]), return_tensors='pt')\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# If you are not on a source install, replace outputs.logits by outputs[0]\n",
        "predictions = F.softmax(outputs[0], dim=-1)\n",
        "\n",
        "thresh = 1e-2\n",
        "vocab_size = predictions.shape[-1]\n",
        "\n",
        "# Predictions has one sentence (index 0) and we look at the last token predicted (-1)\n",
        "idxs = torch.arange(0, vocab_size)[predictions[0][-1] >= thresh]\n",
        "print(tokenizer.convert_ids_to_tokens(idxs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UBMas1uTx_T",
        "outputId": "a139824e-31ec-4cc5-f0ae-a443ebe49bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[',', '.', 'Ċ', 'Ġa', 'Ġthe', 'Ġto', 'Ġof', 'Ġin', 'Ġand', 'Ġbe', 'Ġnot', 'Ġhave']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Eval"
      ],
      "metadata": {
        "id": "DJyZxfIVBFxz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEmq8hKL2Lmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a26a0a-cbf2-44f7-c646-6f453000e1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1780 222 223\n",
            "Test Accuracy: 0.946\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(DATA_FILE_DIR + 'bbc-text.csv')\n",
        "# df = pd.read_csv(DATA_FILE_DIR + 'bbc-text-small.csv') # smaller dataset to save training time.\n",
        "\n",
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=35),\n",
        "                                     [int(0.8*len(df)), int(0.9*len(df))])\n",
        "print(len(df_train), len(df_val), len(df_test))\n",
        "\n",
        "\n",
        "# load trained model\n",
        "gpt2_fast_omp = GPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128)\n",
        "gpt2_fast_omp.load_state_dict(torch.load(STATE_FILE_DIR+\"gpt2_state_w_finetuning.pt\"))\n",
        "gpt2_fast_omp.eval()\n",
        "test_accuracy = eval_model(gpt2_fast_omp, df_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#10% of Coefficients are Non-zero - TESTS"
      ],
      "metadata": {
        "id": "u4F6aWkzD8ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT2 Test - Replace each layer untouching the others**\n",
        "\n",
        "```\n",
        "  gpt2_fast_omp_st = gpt2_fast_omp.gpt2model.state_dict() # GPT2 model state dictionary\n",
        "  y_tensor = gpt2_fast_omp_st[f\"h.{i-1}.mlp.c_fc.weight\"].detach().to(device) # get weights for ith ff layer \n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "AlANW1sFC6YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "# Replace every state untouching the others\n",
        "emb1 = gpt2_fast_omp.gpt2model.get_input_embeddings() # embeddings\n",
        "gpt2_fast_omp_st = gpt2_fast_omp.gpt2model.state_dict() # model state dictionary\n",
        "\n",
        "X_tensor = emb1.weight.detach().to(device) \n",
        "num_features = X_tensor.shape[1]\n",
        "n_non_zero = max(int(0.1 * num_features), 1) # 10% of X num of features\n",
        "\n",
        "exp_results = dict()\n",
        "\n",
        "\n",
        "for i in range(13):\n",
        "  torch.cuda.empty_cache() # Clear memory\n",
        "  gpt2_fast_omp.load_state_dict(torch.load(STATE_FILE_DIR+\"gpt2_state_w_finetuning.pt\")) # load trained weights\n",
        "\n",
        "  if i == 0:\n",
        "    print(\"Results Before Replacement\")\n",
        "    res = eval_model(gpt2_fast_omp, df_test)\n",
        "    exp_results[f'No_Replace'] = res\n",
        "    continue\n",
        "\n",
        "  gpt2_fast_omp_st = gpt2_fast_omp.gpt2model.state_dict() # GPT2 model state dictionary\n",
        "  y_tensor = gpt2_fast_omp_st[f\"h.{i-1}.mlp.c_fc.weight\"].detach().to(device) # get weights for ith ff layer \n",
        "\n",
        "  xes = run_omp(X_tensor,  y_tensor, n_non_zero) # run fast OMP\n",
        "\n",
        "  temp_weights = xes @ X_tensor # matrix mult to get the weights\n",
        "\n",
        "  gpt2_fast_omp_st[f\"h.{i-1}.mlp.c_fc.weight\"]  = temp_weights\n",
        "  gpt2_fast_omp.gpt2model.load_state_dict(gpt2_fast_omp_st)\n",
        "  print(f\"Results for layer-{i-1} Weights Replacement\")\n",
        "  res = eval_model(gpt2_fast_omp, df_test)\n",
        "  exp_results[f'layer-{i-1}'] = res\n",
        "\n",
        "\n",
        "  y_tensor.to(\"cpu\")\n",
        "\n",
        "pd.DataFrame.from_dict(exp_results).to_excel(f'/content/drive/MyDrive/NLP-Final/experiments_results/GPT2/Replace_each_layer_leaving_others_untouched.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "sioqAT8zCryd",
        "outputId": "6c2c002e-110d-403e-f06d-dec25fda8316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Before Replacement\n",
            "Test Accuracy: 0.946\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-32e25dbd8f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0my_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_fast_omp_st\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"h.{i-1}.mlp.c_fc.weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get weights for ith ff layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_omp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_non_zero\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run fast OMP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mtemp_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxes\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX_tensor\u001b[0m \u001b[0;31m# matrix mult to get the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-28a19464ad8f>\u001b[0m in \u001b[0;36mrun_omp\u001b[0;34m(X, y, n_nonzero_coefs, precompute, tol, normalize, fit_intercept, alg)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# If n_nonzero_coefs is equal to M, one should just return lstsq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'naive'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXTX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'v0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_v0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXTX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-28a19464ad8f>\u001b[0m in \u001b[0;36momp_naive\u001b[0;34m(X, y, n_nonzero_coefs, tol, XTX)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Trade b*k^2+bk+bkM = O(bkM) memory for much less compute time. (This has to be done anyways since we are batching,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# otherwise one could just permute columns of X in-place as in https://github.com/scikit-learn/scikit-learn/blob/15a949460dbf19e5e196b8ef48f9712b72a3b3c3/sklearn/linear_model/_omp.py#L28 )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mATs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mATys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mATAs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 10.93 GiB (GPU 0; 11.17 GiB total capacity; 168.70 MiB already allocated; 10.39 GiB free; 190.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT Test - Replace layers one by one together**\n",
        "\n",
        "```\n",
        "    y_tensor = bert1_st[f\"encoder.layer.{i-1}.intermediate.dense.weight\"].detach().to(device) # get weights for ith ff layer\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "fWaZn2XjDXL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Replace layers one by one together\n",
        "emb1 = gpt2_fast_omp.gpt2model.get_input_embeddings() # embeddings\n",
        "gpt2_fast_omp_st = gpt2_fast_omp.gpt2model.state_dict() # model state dictionary\n",
        "\n",
        "X_tensor = emb1.weight.detach().to(device) \n",
        "num_features = X_tensor.shape[1]\n",
        "\n",
        "ratios = [0.01,0.02,0.05,0.1,0.15,0.2,0.25]\n",
        "for j in ratios:\n",
        "  n_non_zero = max(int(j * num_features), 1)+1 # 10% of X num of features\n",
        "\n",
        "  print(f'{100*j:.2f}% Sparsity - {n_non_zero} coef.')\n",
        "  exp_results = dict()\n",
        "  for i in range(13):\n",
        "    torch.cuda.empty_cache() # Clear memory\n",
        "    gpt2_fast_omp.load_state_dict(torch.load(STATE_FILE_DIR+\"gpt2_state_w_finetuning.pt\")) # load trained weights\n",
        "\n",
        "    if i == 0:\n",
        "      print(\"Results Before Replacement\")\n",
        "      res = eval_model(gpt2_fast_omp, df_test)\n",
        "      exp_results[f'No_Replace'] = res\n",
        "      continue\n",
        "\n",
        "    # gpt2_fast_omp_st is updated every step\n",
        "    y_tensor = gpt2_fast_omp_st[f\"h.{i-1}.mlp.c_fc.weight\"].detach().to(device) # get weights for ith ff layer \n",
        "\n",
        "    xes = run_omp(X_tensor.T,  y_tensor, n_non_zero) # run fast OMP\n",
        "\n",
        "    temp_weights = xes @ X_tensor # matrix mult to get the weights\n",
        "\n",
        "    gpt2_fast_omp_st[f\"h.{i-1}.mlp.c_fc.weight\"]  = temp_weights\n",
        "    gpt2_fast_omp.gpt2model.load_state_dict(gpt2_fast_omp_st)\n",
        "    print(f\"Results for Replacing all the layers up to layer-{i-1} (included) \")\n",
        "    res = eval_model(gpt2_fast_omp, df_test)\n",
        "    exp_results[f'layer0_to_{i}'] = res\n",
        "\n",
        "  pd.DataFrame.from_dict(exp_results).to_excel(f'/content/drive/MyDrive/NLP-Final/experiments_results/GPT2/Replace_layers_one_by_one_{100*j:.2f}_percent_{n_non_zero}_coef.xlsx')"
      ],
      "metadata": {
        "id": "a2o0TSXg7zwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Different Sparsity Levels - Run Alone - No GPU Memory for all the EXP together - TESTS"
      ],
      "metadata": {
        "id": "POS_ksPJJkrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT2 Test - Replace only for each layer untouching others, and change num of Non Zero Coefficients**\n",
        "\n",
        "\n",
        "```\n",
        "  # Change ratio of non_zero_coef each iteration\n",
        "  n_non_zero = max(int(ratio * num_features), 1) # ratio of X num of features\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "V5iOxfYvH1Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1%-45%\n",
        "import gc \n",
        "emb1 = gpt2_fast_omp.gpt2model.get_input_embeddings() # embeddings\n",
        "gpt2_fast_omp_st = gpt2_fast_omp.gpt2model.state_dict() # model state dictionary\n",
        "\n",
        "X_tensor = emb1.weight.detach().to(device) \n",
        "num_features = X_tensor.shape[1]\n",
        "\n",
        "exp_results = dict()\n",
        "\n",
        "ratios = [0.0,0.01,0.05,0.1,0.15,0.2,0.3,0.35,0.4,0.45]\n",
        "\n",
        "for j in range (12):\n",
        "  gc.collect()\n",
        "  exp_results = dict()\n",
        "  for i, ratio in enumerate(ratios):\n",
        "    # Change ratio of non_zero_coef each iteration\n",
        "    n_non_zero = max(int(ratio * num_features), 1) # ratio of X num of features\n",
        "    torch.cuda.empty_cache() # Clear memory\n",
        "    \n",
        "    gpt2_fast_omp.load_state_dict(torch.load(STATE_FILE_DIR+\"gpt2_state_w_finetuning.pt\")) # load trained weights\n",
        "\n",
        "    if i == 0: # print baseline results first\n",
        "      print(\"Results Before Replacement\")\n",
        "      res = eval_model(gpt2_fast_omp, df_test)\n",
        "      exp_results[f'No_Replace'] = res\n",
        "      continue\n",
        "\n",
        "    gpt2_fast_omp_st = gpt2_fast_omp.gpt2model.state_dict() # model state dictionary\n",
        "    y_tensor = gpt2_fast_omp_st[f\"h.{i-1}.mlp.c_fc.weight\"].detach().to(device) # get weights for ith ff layer \n",
        "\n",
        "    xes = run_omp(X_tensor.T,  y_tensor, n_non_zero) # run fast OMP\n",
        "\n",
        "    temp_weights = xes @ X_tensor # matrix mult to get the weights\n",
        "\n",
        "    gpt2_fast_omp_st[f\"h.{i-1}.mlp.c_fc.weight\"]  = temp_weights\n",
        "    gpt2_fast_omp.gpt2model.load_state_dict(gpt2_fast_omp_st)\n",
        "    print(f\"Results for layer-{j} Weights Replacement with {100*ratio:.2f}% Non-Zero Coefficients\")\n",
        "\n",
        "    res = eval_model(gpt2_fast_omp, df_test)\n",
        "    exp_results[f'layer0_to_{i}'] = res\n",
        "    y_tensor.to(\"cpu\")\n",
        "\n",
        "  pd.DataFrame.from_dict(exp_results).to_excel(f'/content/drive/MyDrive/NLP-Final/experiments_results/GPT2/Sparsity_Levels_1_45_layer{j}.xlsx')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "uwd200vV-oMo",
        "outputId": "072760d7-f7e3-4ec3-92eb-31fb85244263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Before Replacement\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1bb2a4403acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# print baseline results first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results Before Replacement\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-f0c98039924a>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m           \u001b[0mnumpy_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mmodel_predicted\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wDH2t9H0R3LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "NrOA7IrrA8Hi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl4v3KDozPpn"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATA_FILE_DIR + 'bbc-text.csv')\n",
        "# df = pd.read_csv(DATA_FILE_DIR + 'bbc-text-small.csv') # smaller dataset to save training time.\n",
        "\n",
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=35),\n",
        "                                     [int(0.8*len(df)), int(0.9*len(df))])\n",
        "print(len(df_train), len(df_val), len(df_test))\n",
        "\n",
        "EPOCHS = 2\n",
        "model = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
        "LR = 1e-5\n",
        "\n",
        "train_model(model, df_train, df_val, LR, EPOCHS)\n",
        "\n",
        "true_labels, pred_labels = eval_model(model, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEy3NHRrz7bD"
      },
      "outputs": [],
      "source": [
        "# save trained model\n",
        "torch.save(model.state_dict(), STATE_FILE_DIR+\"gpt2_state_w_finetuning.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SKlearn Test"
      ],
      "metadata": {
        "id": "IvXcD4jWUrLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "\n",
        "emb1 = gpt2.gpt2model.get_input_embeddings() # embeddings\n",
        "X = emb1.weight.detach()\n",
        "num_features = X.shape[1]\n",
        "n_non_zero = max(int(0.1 * num_features), 1) # 10% of X num of features\n",
        "\n",
        "gpt2_st = gpt2.gpt2model.state_dict() # model state dictionary\n",
        "\n",
        "torch.cuda.empty_cache() # Clear memory\n",
        "\n",
        "y = gpt2_st[f\"h.0.mlp.c_fc.weight\"].detach() # get weights for 0 ff layer\n",
        "reg = OrthogonalMatchingPursuit(normalize=False).fit(X.T.cpu(),  y.cpu())\n",
        "xes = reg.predict(X.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vezqd3Iqchs",
        "outputId": "4c714f33-8d6d-4a96-e8ba-f0b7a73d2e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
            "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import savetxt, loadtxt\n",
        "savetxt(f\"/content/drive/MyDrive/NLP-Final/results_omp_gpt2_layer0.csv\", xes, delimiter=',')"
      ],
      "metadata": {
        "id": "FVZOGzs1cax8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Z6YmSo3pev",
        "outputId": "a94b8063-3021-4323-e26b-8af6655e2a7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gpt2model.h.0.mlp.c_fc.weight\n",
            "gpt2model.h.1.mlp.c_fc.weight\n",
            "gpt2model.h.2.mlp.c_fc.weight\n",
            "gpt2model.h.3.mlp.c_fc.weight\n",
            "gpt2model.h.4.mlp.c_fc.weight\n",
            "gpt2model.h.5.mlp.c_fc.weight\n",
            "gpt2model.h.6.mlp.c_fc.weight\n",
            "gpt2model.h.7.mlp.c_fc.weight\n",
            "gpt2model.h.8.mlp.c_fc.weight\n",
            "gpt2model.h.9.mlp.c_fc.weight\n",
            "gpt2model.h.10.mlp.c_fc.weight\n",
            "gpt2model.h.11.mlp.c_fc.weight\n"
          ]
        }
      ],
      "source": [
        "def print_layers_params(model):\n",
        "  for name,x in model.named_parameters():\n",
        "   # if \"mlp.c_fc.weight\" in name: # c_fc is the feed forward part of the layer \n",
        "      print(name)\n",
        "\n",
        "print_layers_params(model_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fast OMP Test"
      ],
      "metadata": {
        "id": "xrTVGgSYUud4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "gpt2_fast_omp = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128)\n",
        "gpt2_fast_omp.load_state_dict(torch.load(STATE_FILE_DIR+\"gpt2_state_w_finetuning.pt\"))\n",
        "gpt2_fast_omp.eval()\n",
        "\n",
        "emb1 = gpt2_fast_omp.gpt2model.get_input_embeddings() # embeddings\n",
        "X_tensor = emb1.weight.detach().to(device) \n",
        "num_features = X_tensor.shape[1]\n",
        "n_non_zero = max(int(0.1 * num_features), 1) # 10% of X num of features\n",
        "\n",
        "gpt2_fast_omp_st = gpt2_fast_omp.gpt2model.state_dict() # model state dictionary\n",
        "\n",
        "torch.cuda.empty_cache() # Clear memory\n",
        "\n",
        "y_tensor = gpt2_fast_omp_st[f\"h.0.mlp.c_fc.weight\"].detach().to(device) # get weights for 0 ff layer\n",
        "\n",
        "xes = run_omp(X_tensor.T,  y_tensor.T, n_non_zero) # run fast OMP\n",
        "temp_weights = xes @ X_tensor # matrix mult to get the weights"
      ],
      "metadata": {
        "id": "WChC3J7uqOXc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "daa7923b-b663-4054-dace-5cf55bbad80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-22b9263d9b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0my_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_fast_omp_st\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"h.0.mlp.c_fc.weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get weights for 0 ff layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_omp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_non_zero\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run fast OMP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtemp_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxes\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX_tensor\u001b[0m \u001b[0;31m# matrix mult to get the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-28a19464ad8f>\u001b[0m in \u001b[0;36mrun_omp\u001b[0;34m(X, y, n_nonzero_coefs, precompute, tol, normalize, fit_intercept, alg)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# If n_nonzero_coefs is equal to M, one should just return lstsq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'naive'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXTX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'v0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0momp_v0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXTX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-28a19464ad8f>\u001b[0m in \u001b[0;36momp_naive\u001b[0;34m(X, y, n_nonzero_coefs, tol, XTX)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0margmax_blast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mprojections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sum is just a squeeze, but would be relevant in SOMP.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 590.00 MiB (GPU 0; 11.17 GiB total capacity; 10.46 GiB already allocated; 103.81 MiB free; 10.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_fast_omp_st[f\"h.0.mlp.c_fc.weight\"]  = temp_weights.T\n",
        "gpt2_fast_omp.gpt2model.load_state_dict(gpt2_fast_omp_st)\n",
        "print(f\"Results for layer 0 Weights Replacement\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "tx8pd9DgYsDv",
        "outputId": "215a3eb8-d63d-4d70-a3b0-fadd8d0708a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for layer 0 Weights Replacement\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-32b852ce0b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgpt2_fast_omp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpt2model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpt2_fast_omp_st\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Results for layer 0 Weights Replacement\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpt2_fast_omp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: eval_model() missing 1 required positional argument: 'test_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATA_FILE_DIR + 'bbc-text.csv')\n",
        "# df = pd.read_csv(DATA_FILE_DIR + 'bbc-text-small.csv') # smaller dataset to save training time.\n",
        "\n",
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=35),\n",
        "                                     [int(0.8*len(df)), int(0.9*len(df))])\n",
        "test_accuracy = eval_model(gpt2_fast_omp, df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPswtzLMaj-_",
        "outputId": "29705fc4-7058-44f0-e29c-917787d53f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.946\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xEUs64r2Chb2",
        "PvpKt_-tBWJ2",
        "qggWM8tyYNMr",
        "PFe-P-eNVKDc",
        "u4F6aWkzD8ON",
        "POS_ksPJJkrc",
        "NrOA7IrrA8Hi",
        "IvXcD4jWUrLw"
      ],
      "name": "GPT2 - Experiments.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}